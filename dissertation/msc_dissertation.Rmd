---
title: |
  | __How analysis strategy affects analysis results__
subtitle: |
  | *Defining the results space in @silberzahn2018 through model specification*
  |
  | Master's thesis - DRAFT
author: "Sebastian Ploner, sploner1@sheffield.ac.uk, University of Sheffield"
linestretch: 1.5
output:
    pdf_document:
        includes:
            in_header: header.tex
        fig_caption: yes
urlcolor: blue
bibliography: references.bib
csl: apa.csl
header-includes:
  - \usepackage[ruled,vlined]{algorithm2e}
  - \usepackage{float}
  - \usepackage{caption}
  - \captionsetup[figure]{font={stretch=1}}
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE, fig.pos = 'H')

#...............................................# Set parameters #..............................................#

# This script can be run in its entirety to reproduce the specification curve analysis for one population at a time. 
# Please read the comments in this section to understand what each parameter does.
# After setting the parameters for the first time, we recommend reading the WARNINGS on lines 1 and 56 before
# sourcing the entire script or running the "Prepare R Session" section.

#... Set seed for random number generation
set.seed(999999) # set to 999999 to reproduce the results reported in the paper


#...........................................# Prepare R Session #...............................................#

# WARNING: All currently loaded packages will be detached and packages needed 
#          to run this script will be loaded. 
#          Missing packages will be downloaded and installed.
#          Also, the working directory will be automatically set to the location of this script.
#          If you did not alter the structure of the folder containing this script and the data,
#          in most cases you should be able to run this script without any manual adjustments 
#          in a current version of RStudio (tested in RStudio Version 1.1.453 and newer releases running 
#          R Version 3.5.1 and newer releases).


# Detach packages
if(!is.null(sessionInfo()$otherPkgs)) {
  invisible(lapply(paste("package:", names(sessionInfo()$otherPkgs), sep = ""), 
                   detach, character.only = TRUE, unload = TRUE))
}


# Download and install missing packages
requiredPackages = c("here", "data.table", "tidyverse", "PupillometryR", "cowplot", "knitr", "DiagrammeR")

missingPackages = requiredPackages[!requiredPackages %in% installed.packages()[ , "Package"]]

if(length(missingPackages)) {
  install.packages(missingPackages)
}


# Load required packages
invisible(lapply(requiredPackages, require, character.only = TRUE))


# Load data
## prepared data
dat = data.frame(fread(here::here("data", "3_prepared_data.csv")))

## Outcomes of running the 1,000 models
dat_models_specifications = data.frame(fread(here::here("data", "4_model_outcomes_specifications_merged.csv")))

## Outcome of running the "meta-ANOVA" to get the covariates' specified effects
dat_covariates = data.frame(fread(here::here("data", "4_covariate_effect_data.csv")))


# Adjusting class for proper visualisation
dat_models_specifications$below_alpha = factor(dat_models_specifications$below_alpha)

dat_covariates$impact_names = factor(dat_covariates$impact_names)
dat_covariates$below_alpha = factor(dat_covariates$below_alpha)

```

```{=latex}

% Trigger ToC creation in LaTeX
\renewcommand{\baselinestretch}{1.5}\normalsize
\tableofcontents
\renewcommand{\baselinestretch}{1.5}\normalsize

```

... \newline
*Abstract--in progress.* \newline
... \newline


\newpage


# Introduction
## Theoretical framework
     The Covid-19 pandemic has reaffirmed the need for sound scientific research to inform decision-making on a scientific and societal level [@collins2021]. Rigorous research builds upon a systematic and well-reasoned approach to solving a research problem. Based on available literature, a falsifiable research question is defined and a corresponding hypothesis is developed. An appropriate study is then designed and conducted. To draw inferences from the gathered data, statistical models are developed and the effect of each variable is assessed. Every one of these steps is influenced by the decisions researchers make, which are known as *researcher degrees of freedom* [RDF, @simmons2011; @wicherts2016]. Usually there are many feasible analytical strategies to answering a research question and none of them are inherently right or wrong  [@carp2012]. This often creates uncertainty, for example, about what covariates to include and how to model them, which in turn leads to inconsistent findings [@patel2015; @ioannidis2008]. Recently, efforts have been made to better understand the scope of variation induced by different analytical strategies.

     These efforts include crowdsourcing approaches to data analysis [@silberzahn2018; @botvinik-nezer2020]. Its premise is to have a large number of researchers team up into to smaller, independent groups to investigate the same research question based on the same dataset. For instance, @silberzahn2018 had 29 teams investigate the effects of a football player's skin colour on the odds of being sent off the field. The variation between the analytical strategies was substantial. There were 29 different analyses with 21 different combinations of covariates. Twenty teams found a statistically significant effect. The authors also controlled for researchers' prior believes and experience as well as peer-rated analysis quality, none of which accounted for the variation of results. @botvinik-nezer2020 made similar observations. Crowdsourcing projects excels at emphasising the substantial impact of different analytical strategies, but they are also extremely time and personnel intensive. The two mentioned studies lasted between 2 to 3+ years, and included 61 and 180 analysts, respectively. Additionally, despite covering a more diverse set of analytical strategies than a single conventional analysis, crowdsourcing is limited by the number of participating teams. It, therefore, still only covers a few selected strategies, not all possible ones. 

     @silberzahn2018 and @botvinik-nezer2020, therefore, suggest using multiverse analysis (also known as specification-curve analysis) as an alternative to crowdsourcing. This approach requires identifying and running all plausible analytical strategies. Plausible strategies are defined as statistically valid, non-redundant, tests appropriate to the research question. Their aggregated results are then used to make inferences about the research question. Despite being statistically more complex and computationally more intense, this approach has the advantages of only needing one, or ideally a couple, researchers. Moreover, a researcher's inherent strategy bias is neutralised and noise is made transparent [@simonsohn2020]. Multiverse approaches are therefore well suited for assessing the scope of variation induced by different analytical strategies. However, one aspect has been, to my knowledge, neglected thus far. To properly assess the scope of variation it needs to be contextualised. That is, the space in which it can vary needs to be defined in order to understand to what degree the scope covers the space. The concept of statistical association provides a suitable analogy. Covariation and correlation both indicate the direction of relationship (positive, null, negative), however, only correlation allows for assessing the association's strength. Correlation is the standardised version of covariation, and only knowing the its limits gives the correlation coefficient meaning. The same principle applies to analyses on a broader level.

## Current project
     Taken together, researchers make many analytical decisions throughout conducting a study introducing so-called *researcher degrees of freedom*. Crowdsourcing analysis presents a strategy to understand their induced variation, but is impractical due to its time and personnel requirements, and is still limited by the number of participating teams. Multiverse analysis present a promising, low-personnel, but computationally intense alternative to assessing the scope this variation. Despite observing substantial variation in crowdsourced data analysis projects, little is known about the extend to which these approaches cover the full range of possible results. Determining the full results space and its underlying mechanisms is an important exercise to understand the impact of analytical strategies. To my knowledge no previous study has attempted to define and understand a study's entire results space. In this project, running all possible analytical strategies, I, therefore, aim to define and understand the results space of @silberzahn2018. By doing so, I hope further the understanding of how an analytic strategy affects its result.


# Analysis
## Analysis plan
     The project's objective is to define the results space of the @silberzahn2018 to draw conclusions about the mechanisms of multiverse analysis. The results space refers to the numerical interval between the lowest and highest possible outcome. It is created by running every possible analytical strategy. Hence, it is closely related to assessing an effect's robustness. Robustness refers to an effect's consistency under different model specifications. @patel2015 developed a standardised approach to assessing an effect's robustness which they termed assessing the *vibration of effect*. I will therefore use this standardised approach to define the results space. The approach essentially comprises two parameters: the statistical models and the covariates (or control variables). In @silberzahn2018 the analysts used numerous different statistical models like multiple linear regression, mixed-model logistic regression or Bayesian logistic regression. In total there were 29 different modelling approaches. Additionally, each team used a different set of covariates. Across all teams there 15 covariates used. This gives $2^n$ i.e., $2^{15} = 32,768$ possible combinations of covariates. Adding all modelling possibilities to the equation gives a total of $29 * 2^{15} = 950,272$ combinations to run. This number exceeds the project's scope, hence, it needs to be reduce to a more manageable count. I am, therefore, focusing on one modelling approach. In particular, on the approach that produced the median outcome of all analyses. The median, being the middle number of any set of values, is a reasonable starting point in order to estimate the results space. Nevertheless, even focusing on one analytical approach still leaves $1 * 2^{15} = 32,768$ possibilities. Due to computational limitations I will first run a sample of 200, followed by a sample of 1,000 combinations. If there's a substantial difference between the median and the spread I will run more models, if not, I will make the assumption that 1,000 reasonably estimates all ~33k combinations.

     In @silberzahn2018 the median outcome was produced by @team23 which will hereinafter be referred to as *team 23* due to it's designated team number in the original study. *Team 23* first transformed the data and then conducted a mixed-model logistic regression. The first step of this project will be replicating the transformation and the analysis. Replicating other researchers analyses has the benefit of checking their work and, if results are indeed replicated, increasing confidence in them. It also ensures that this project has the same starting point as *team 23* did. Given the team made all their scripts publicly available I expect this step to be straightforward. Next is drawing a random sample of covariates, without replacement. "Without replacement" ensures all covariate combinations are unique in the sample. The covariates will be appended to the base (or core) variables. Base variables are those variables that are primarily assessed to answer the research question. In this case whether a football player's skin colour affects the odds of being sent off the field. *Team 23* defined two interaction terms as the base: "skin tone *X* implicit bias" and "skin tone *X* explicit bias". (The variables are described in the "data" section.) Hence, all models will have the following structure:
$$
\begin{aligned}
RedCard = SkinTone*ImplicitBias + SkinTone*ExplicitBias + CovariateCombination_{i}
\end{aligned}
$$ 
While running each model, the relevant statistics will be extracted. Those are the coefficient (or effect) of skin tone, its standard error, test-statistic and p-value. Just as *team 23* did I will then calculate the 95% confidence intervals (CI). The estimates and their CIs are then transformed to odds ratios (OR) through exponentiating them to the power of two. Odds ratios quantify the strength of association between two variables. If greater than one the dependent variable is more likely to occur given the independent variable, if lower than one it less likely.

     These odds ratios will be visualised to assessed through a conventional specification curve plot, a rain-cloud plot and scatter plot. The following describes the three graphs in more detail:

(i) The specification curve plot was developed to be a descriptive plot i.e., raw data is being plotted without any aggregation done. Its objective is to describe the results space while allowing the reader to identify the specified covariates for each outcome [@simonsohn2020]. It therefore has two vertically stacked components. The top part shows a sorted scatter plot. Its horizontal axis shows the models specifications and its vertical axis displays the outcome measure. The scatter points are sorted from lowest to highest outcome measure. This way the lowest outcome measure is on the bottom left corner and the highest in the top right one. The bottom part of the plot represents a table. As in the top plot the horizontal axis holds the model specifications, the vertical axis lists the covariates. This arrangement allows each cell to specify the presence or absence for each covariate in a given specified model. For the top and bottom plot to work together it is imperative that the horizontal axes are identically arranged. If so, for every point in the top plot (i.e., for every outcome) the specified covariates can be seen in the bottom plot. For an example check Figure \ref{fig:sca_plot}. As the current project has 1,000+ specifications it becomes very hard to identify specific covariates given the space limitations. Hence, I to had come up with different more intuitive ways of visualisation.

(ii) The rain-cloud plot was developed by @allen2021. Its objective is to give an unbiased, transparent view on the raw data. It therefore combines a density, box and scatter plot. If stacked vertically from top to bottom, respectively, they look like a cloud with rain drops, hence, its name. The advantage of this plot is to be able to assess the raw data including key statistics (median, 25th and 75th quartiles and CIs) as well as the probability density all in one succinct plot. The current project seeks to define and describe a results space the rain-cloud plot is, therefore, the ideal choice of graphs. (For an example check the results section.) Unfortunately, the plot does not allow to identify the covariates giving rise to the outcomes or their specified effects. As the project also seeks to understand the mechanisms of multiverse analysis it important to get insights about the specified covariates effects. Therefore a third plot is developed which is to be assessed in tandem with this plot.

(iii) The third and final plot is a sorted scatter plot. While there is nothing special about the plot itself its content is important. Given the very high number of models that are run, it does not make sense to assess each model and its effects in isolation. Instead the effects for each covariates need to be aggregated. Hence, the goal of this plot is to visualise the specified effect for each covariate. Prior to doing so, the covariates first need to be aggregated and their specified effects need to be calculated. To this end, each covariate is recoded into a binary factor: included in the model yes/no. This newly defined factors are than used as an independent variables in an ANOVA. The previously calculated odds rations are used as dependent variables. The estimates of the fitted model are the specified effect for each covariates. These are visualised similarly to the top part of the specification curve plot. The covariates are on the horizontal axis, will the odds ratios are on the vertical axis. Here too, the lowest outcome is in the bottom left corner and the highest outcome in the top right one. Additionally the point are coloured indicating a statistically significant effect (or non-significant).

     Taken together, the current project's objective is to define the results space of @silberzahn2018 in order to make inferences about the underlying mechanisms of multiverse analysis. The results space is created by running all possible model and covariate combinations. Applied to @silberzahn2018 this means running roughly 1M models. Due to time and computational limitations, I am focusing on the model that produced the median outcome of all analytical strategies. Hence, I will run a mixed-model logistic regression with 1,000 randomly sampled covariate combinations. For each model relevant statistics will extracted and visualised. The conventional specification curve plot does not deal well with a large number of model specifications. Therefore, I will produce a rain-cloud and scatter plot, which visualise the results space (and its distribution) as well as the specified covariate effects, respectively. For the latter, I will first have to run an additional statistical model to calculate the specified effects. These graphs will give insight into the results space, its building blocks and ultimately into the mechanisms of multiverse analysis.

## Code
     This section provides a brief overview of the code and explains the reasoning behind it. As mentioned in the analysis section the first step was replicating the data transformation and analysis of *team 23* [@team23]. The team made their project folder publicly available. It contains three scripts relevant to this project: the data exploration, transformation and analysis. After duplicating their project folder on my local hard drive all scripts run without issues (only the working directories needed adjustment). The data exploration included the reasoning behind transforming the data and some cleaning. The data transformation restructured the data into a more intuitive format (more details on the topics of exploration and transformation are in the data section). The analysis script prepared the data by assigning variables classes (factors, numerical or boolean) and standardised a few variables i.e., they were centred around the mean. Finally, the models were specified. The team ran both frequentist and Bayesian models, however, this project covers the frequentist approach, only.

     My code is based on @haessler2020 and @patel2015. The rough structure of the code is shown in the pseudocode table (Figure X). Here, I am briefly motivating two analytical choices I made. For a closer look please check the commented code itself:

(i) Choosing the function to run the statistical model. *Team 23* ran a mixed-model logistic regression. This model has two relevant components to this explanation: fixed effects and random effects. Fixed effects are those that are consistently observed in different situations because the construct is of direct interest to the research question. In this case, it is, for example, skin tone. Independent of the player, the game or the league skin tone is always observed. Their counter parts are random effects which change between situations. A player, for example, is just one "unit" a measurement, and is himself not directly relevant to answering the research question. The function used by *team 23* requires to specify a random effect. However, given the project seeks to sample from all possible covariate combinations, a random effect is not always included. Hence, the "non-random" counter part to this function needs to be utilised. For this project, it was important to check that both functions use the same estimation method (maximum likelihood or restricted maximum likelihood estimation) to calculate the statistics. It was important to check to ensure the outcomes are comparable.

(ii) No multiple comparison. This is based on the fact that in statistics null hypotheses are one rejected if the probability of finding a false positive is below 5% (known as the significance level, $\alpha$). The more statistical tests a run, the more likely it is that one of those tests is indeed a false positive. Hence, the are techniques that account of this issue. It is usually good practice to account for those "multiple comparisons". Here, I refrained from doing so though. This project seeks to simulate multiple researchers running different models. Therefore, for the the purpose of this project all models are run independently by individual researchers. Those would not have knowledge of the other analyses and, hence, would not account for them. To main the highest possible ecological validity, I therefore did not account of multiple comparisons.

\begin{algorithm}
\caption{Pseudocode overview--in progress}
\DontPrintSemicolon
\SetAlgoLined
\KwData{Prepared data based on team 23 script}
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output} 
$variables$ $\leftarrow$ Define dependent, base variables and covariates \\
$specifications$ $\leftarrow$ Use $variables$ to create matrix containing all possible covariate combinations \\
$formula$ $\leftarrow$ Paste $specifications$ by row and append as column to $specifications$ \\
$formula.ranef; formula.ef$ $\leftarrow$ Separate formulas based on including a random-structure \\
$samlple.ranef; sample.ef$ $\leftarrow$ Random, without replacement, sample from $formula.ranef; formula.ef$
\BlankLine
 initialization\;
  \While{not at end of this document}{
    read current\;
    \eIf{understand}{
      go to next section\;
      current section becomes this one\;
      }{
      go back to the beginning of current section\;
      }
    }
\KwResult{List containing model statistics}
\end{algorithm} 

     The code is written in R (Version 1.4.1103) on macOS Big Sur (Version 11.4) and can be retrieved from my [GitHub repository](https://github.com/sebastianplnr/msc_dissertation_project). The code from *team 23* [@team23] can be retrieved from their [OSF repository](https://osf.io/akqt4/). Following R packages were used *here 1.0.1* [@here], *data.table 1.14.0* [@datatable], *tidyverse 1.3.1* [@tidyverse], *lme4 1.1-27.1* [@lme4], *pbmcapply 1.5.0* [@pbmcapply], *PupillometryR 0.0.3* [@PupillometryR] and *cowplot 1.1.1* [@cowplot].


## Data description and preparation
     The data was retrieved from @silberzahn2018. It contains information about football players, their encounters with referees and the received cards (yellow, yellow/red and red). Moreover, a player's position, age, club, league country, victories, ties, defeats and goals. In addition, a skin tone rating based on two independent raters was included. The referees are numerically coded to protect their identify. The referees origin countries are also included as well as an implicit and explicit racism bias scores for their respective countries. The exploratory data analysis (EDA) of *team 23* showed that each row of the dataset represents a unique player-referee combination listing all their encounters as well as the couple's total number of received/assigned cards. The team states that it preferred a different data format. More specifically, a format where each player-referee encounter is reflected by one row. This way each encounter had a maximum of one red card. To achieve this format the data had to be "disaggregated" i.e., transformed. Further EDA showed that receiving a red card is highly unlikely, 0.008%, i.e., data is highly skewed. This property informed the teams decision to use a type of logistic regression (a statistical modelling technique equipped to deal with skewed/binary distributions). Finally, the team excluded all referee that did have at least 22 encounters. Their reasoning was a game includes (at least) 22 players, 11 players per team, if this were not the case referee most likely did not officiate in one for the four leagues of interest (England, Germany, Italy and Spain). This step excluded roughly 66% of the referees but retained 97.4% of the cases. The final dataset used for the current project contained 335,537 observations and 19 variables. Figure \ref{fig:var_plots} shows the properties of the variables relevant to current project's analysis \newline

```{r var_plots, echo = FALSE, fig.width = 8, fig.align = "center", fig.cap = "A) Showing the strong skew of receiving no red to receiving a red card. B) Showing most players had a lower skin tone rating i.e., most players were on the whiter side. C) Showing there is not much variation in implict racial scores. D) Showing more variation in explitic reacial bias scores. The latter two were centred around the mean, hence, zero does not mean there is no bias."}

red_card_plot = dat %>% ggplot(aes(factor(all_reds))) +
  geom_bar() +
  xlab("Red card") +
  scale_y_continuous(name = "Count", labels = function(x) format(x, big.mark = ",", scientific = FALSE)) +
  theme_classic() +
  theme(panel.grid.major.y = element_line(colour = "grey"), text = element_text(size = 10))

skin_tone_num_plot = dat %>% ggplot(aes(skin_tone_num)) +
  geom_density() +
  scale_x_continuous(name = "Skin tone rating") +
  scale_y_continuous(name = "Density", breaks = c(seq(0, 8, 2)), limits = c(0, 8)) +
  theme_classic() +
  theme(panel.grid.major.y = element_line(colour = "grey"), text = element_text(size = 10))

imp_bias_plot = dat %>% ggplot(aes(imp_bias)) + 
  geom_density(adjust = 2) +
  scale_x_continuous(name = "Implicit racial bias", breaks = c(seq(-2, 2, 1)), limits = c(-2, 2)) +
  scale_y_continuous(name = "Density", breaks = c(seq(0, 40, 10)), limits = c(0, 40)) +
  theme_classic() +
  theme(panel.grid.major.y = element_line(colour = "grey"), text = element_text(size = 10))

exp_bias_plot = dat %>% ggplot(aes(exp_bias)) +
  geom_density(adjust = 2) + 
  scale_x_continuous(name = "Explicit racial bias", breaks = c(seq(-2, 2, 1)), limits = c(-2, 2)) +
  scale_y_continuous(name = "Density", breaks = c(seq(0, 40, 10)), limits = c(0, 40)) +
  theme_classic() +
  theme(panel.grid.major.y = element_line(colour = "grey"), text = element_text(size = 10))

plot_grid(red_card_plot, skin_tone_num_plot, imp_bias_plot, exp_bias_plot, labels = "AUTO")

```



# Results
## Replicating *Team 23* analysis
     As mentioned in the above section the first steps were replicating the *team 23* analysis using their provided scripts. The results are reproducible without any adjustment. Skin tone has a significant effect on the odds of being send off the field ($OR = 1.311$, 95%CI [1.099, 1.563], $p = 0.003$). This means while keeping all other variables constant for every unit increase in skin tone rating (darker skin tone), the odds of being send off the field increase by roughly 131%. The interaction terms of skin tone and implicit racial bias ($OR = 0.004$, 95%CI [0.000, 23.259], $p = 0.211$) as well as skin tone and explicit bias ($OR = 1.837$, 95%CI [0.493, 6.848], $p = 0.365$) are both non-significant. In accordance with the original analysis, there are also significant differences between leagues and positions as well as implicit racial bias scores. Explicit bias scores are on verge of being non-significant. This analysis only aimed at testing reproducibility, which proved to be true, further results details are forfeited.

## Specification curve
     Shown in Figure \ref{fig:sca_plot}. The horizontal axes of the top and bottom chart show the specifications sorted based on their odds rations from lowest to highest. The odds ratios themselves are shown on the vertical axis of the top plot. The points in the top plot, which look like a line, each represent the outcome of one statistical model. Black points refers to statistical significant, red to non-significant outcomes. Overall are 89.7% of the outcomes significant. Except for the lowest outcome ($OR_{lowest} = 1.080$) are all points close to the their respective neighbours. This indicates that none of the specified models are responsible for a sudden increase in the outcome measure. The relatively smooth line suggest that sampling 1,000 specifications is, in fact, representative for all 33k models. The law of large numbers  The points can be divided into roughly three sections all non-significant ($\leq 57^{th}$), mixture of (non-)significance ($58^{th} - 247^{th}$) and all significance ($\geq 248^{th}$). The bottom table lists all covariates on its vertical axis, sorted from most positive to most negative impact. For example, player has the strongest positive impact, while club has the strongest negative impact. Each column of the table represents one mode. A coloured cell indicates the presence of the variable, an uncoloured cell its absence. Just like a above, black indicates the outcome measure was significant, red non-significance.

     The top and bottom plot work in tandem. Each outcome (i.e., point) in the top corresponds to the indicated covariates in the bottom table. Regular specification curve analyses focus on all *reasonable* specifications, hence, their number of specifications is much lower and one is, in fact, able to tell the different model specifications apart. However, the current project's goal was to define the results space, which requires all *possible* specifications. The specifications are therefore huddled extremely closely which does not allow the plot to functions in its supposed way. Thus, I create two alternative graphs. \newline

```{r sca_plot, echo = FALSE, fig.width = 8, fig.align = "center", fig.cap = "Convential specification curve. Each outcome (i.e., point) in the top corresponds to the indicated covariates in the bottom table. Due to the large number of specifications, this plot is not as informative as it is supposed to be. It is, therefore, merely making an argument for needing and alternative.", warning = FALSE}

# Order by odds ratio, low to high and assign identifier
analysed_specifications = dat_models_specifications[order(dat_models_specifications$estimate_oddsratio), ]
analysed_specifications$id = factor(seq(1:nrow(analysed_specifications)))


# Preparing the bottom part of the SCA plot by transforming wide to long
## Subset covariates and relevant statistics
prepare_long_df = analysed_specifications %>% select(specific_pos:games, id)

## transform wide to long
long_df = melt(data.table(prepare_long_df), "id", variable.names = "covariate")
long_df = long_df[long_df$value == TRUE, c("id", "variable")]

## statistics are still missing (odds ratio and significance)
id_oddsratio_below_alpha = analysed_specifications %>% select(id, estimate_oddsratio, below_alpha, p_value)

## Adding (or joining) the statistics to the long data frame
long_df = data.frame(left_join(long_df, id_oddsratio_below_alpha, by = "id"))


# Assign proper names for visualisation
long_df$variable = factor(long_df$variable,
                           levels = c("club", "victories", "weight_kg", "player_cards_received", "ties", "league_country", "specific_pos", "age_yrs", "ref", "ref_cards_assigned", "goals", "height_cm", "games", "ref_country", "player"),
                           labels = c("Club", "Victories", "Weight", "Cards rec.", "Ties", "League", "Position", "Age", "Referee", "Cards assig.", "Goals", "Height", "Games", "Ref. country", "Player"))


# Covariates should be sorted based in their impact
dat_covariates = dat_covariates[order(dat_covariates$estimate_oddsratio), ]
ordered_covar = dat_covariates$impact_names


# build plot
top = analysed_specifications %>% 
  filter(estimate_oddsratio < 4) %>% 
  ggplot(aes(as.numeric(id), estimate_oddsratio)) +
  geom_point(aes(colour = below_alpha), size = 0.3, alpha = 0.5) +
  geom_ribbon(aes(ymin = ci_lower_oddsratio, ymax = ci_upper_oddsratio), alpha = 0.3) +
  geom_hline(yintercept = 1, color = "black") +
  scale_color_manual(values = c("red", "black")) +
  scale_x_discrete(name = "", expand = c(0.01, 0)) +
  scale_y_continuous(name = "Odds ratio", breaks = c(seq(0.9, 1.7, 0.1)), limits = c(0.89, 1.71), expand = c(0, 0)) +
  labs(title = "Specification curve",
       subtitle = paste0("N = ", nrow(analysed_specifications), ", 95% CI", collapse = "")) +
  theme_classic() +
  theme(panel.grid.major.y = element_line(colour = "grey"),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.line.x = element_blank(),
        plot.margin = unit(c(0, 1, 0, 1), "cm"),
        legend.position = "top",
        legend.justification = "right",
        legend.title.align = 1,
        legend.text = element_text(size = 10),
        legend.direction = "horizontal",
        legend.title = element_blank(),
        legend.margin = margin(t = -0.61, b = -0.2, unit = "cm"),
        legend.box.margin = margin(t = -0.61, b = -0.2, unit = "cm"),
        plot.title = element_text(face = "bold"),
        plot.subtitle = element_text(face = "italic", margin = margin(0, 0, 20, 0)),
        text = element_text(size = 10)) +
  guides(colour = guide_legend(override.aes = list(alpha = 1, size = 1), reverse = TRUE))

bottom = long_df %>%
  ggplot(aes(x = id, y = factor(variable, levels = ordered_covar))) +
  geom_tile(aes(fill = below_alpha), width = 0.5, height = 0.5, color = "white") +
  scale_fill_manual(values = c("red", "black")) +
  scale_x_discrete(name = "Specifications", expand = c(0.01, 0)) +
  scale_y_discrete(name = "Covariates", expand = c(0.03, 0)) +
  theme_classic() +
  theme(legend.position = "none", 
        axis.ticks.y = element_blank(),
        axis.line.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        plot.margin = unit(c(0, 1, 0.5, 1), "cm"),
        text = element_text(size = 10))

sca_plot = plot_grid(top, bottom, ncol = 1, align = "v")
sca_plot

```


## Results space
     Shown in Figure \ref{fig:rain_cloud_plot}. The horizontal axis shows the odds rations. From top to bottom the three component show the probability density distribution, the box plot and the raw data, respectively. The dashed line indicates the original results of *team 23*, which has also been the median outcome of all analytical strategies in @silberzahn2018. Based on the raw data points, the results space can be defined as the interval between 1.081 and 1.383. The 1st quatile equals to 1.206, the median equals to 1.248 and the 3rd quartile equals to 1.293. Therefore, as also evidenced by the probability density distribution, 50% of the lay withing a very narrow interval (between 1st and 3rd quartile). The outcome of *team 23* (1.31) is still included in the interval, but it is outside the middle 50% of the data.

     The probability density distribution also has an interesting shape, having two peaks. This suggests a particular covariate combination structure causing two focal points. Based on this graph alone though it is not possible to decipher the underlying structure though. What also seem to be more apparent in this graph than in the specification curve is that the non-significant values also seem to revolve round to focal points. One being around 1.13 and the other around 1.19. This also suggest some influential covariate or covariate structure that is cause non-significance.

     Finally, for transparency purpose, it also needs to be mentioned that eight points were excluded from the visualisation. Four of them were "infinite", one effectively approaching infinity, one being in the lowest million range, one being 150, and a final being 4.6. I specifically chose not to include the latter one in the graph as it would despite is relatively close numerical proximity skewed the distribution being at least a visual outlier. \newline

```{r rain_cloud_plot, echo = FALSE, fig.width = 8, fig.align = "center", fig.cap = "The rain cloud plot is comprised of three parts. The probability density distribution, the box plot and the raw data points. This allows for an transparent and bias assessment of the results space and its distribution."}

vibration_of_effect = dat_models_specifications %>%
  filter(estimate_oddsratio < 4) %>% 
  ggplot(aes(x = "", y = estimate_oddsratio)) +
  geom_flat_violin(aes(fill = ""), trim = FALSE, colour = "dark grey", fill = "dark grey") +
  geom_point(aes(x = 0.6, y = estimate_oddsratio, colour = below_alpha),
             position = position_jitter(width = .03, seed = 123), size = 3, shape = 20, alpha = 0.3, stroke = 0) +
  geom_boxplot(aes(x = 0.81, y = estimate_oddsratio), alpha = 0.5, width = 0.1, colour = "black") +
  geom_hline(yintercept = 1.31, linetype = "dashed", color = "black") +
  annotate("text", x = 1.559, y = 1.395, label = "Silberzahn et al. (2018) median OR", color = "black", size = 3.5) +
  scale_color_manual(values = c("red", "black")) +
  scale_y_continuous(name = "Odds ratio", breaks = c(seq(1.0, 1.5, 0.05)), limits = c(0.99, 1.51), expand = c(0, 0)) +
  labs(title = "Results space defined through covariate specification",
       subtitle = paste0("N = ", nrow(dat_models_specifications), ", Odds ratio (OR)", collapse = "")) +
  coord_flip() +
  theme_classic() +
  theme(axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        plot.margin = unit(c(0.5, 1, 0.5, 1), "cm"),
        legend.position = "top",
        legend.justification = "left",
        legend.title.align = 1,
        legend.text = element_text(size = 10),
        legend.direction = "vertical",
        legend.title = element_blank(),
        legend.margin = margin(b = -0.8, unit = "cm"),
        legend.box.margin = margin(b = -0.8, unit = "cm"),
        plot.title = element_text(face = "bold"),
        plot.subtitle = element_text(face = "italic"),
        text = element_text(size = 10)) +
  guides(colour = guide_legend(override.aes = list(alpha = 1), reverse = TRUE))

vibration_of_effect

```


## Specified covariate effects
     The final graph shows the specified covariate effects. On the horizontal axis are the covariates, on the vertical axis the estimates. The covariates are sorted from negative to positive impact. Black indicates a significant effect, red non-significant. The error bars represent the 95% CI. Four out of 15 covariates are significant, roughly 27%. Thought the significant covariates' effects seem relatively weak, ranging from -0.1 to 0.05, only. Interesting is also which covariates are significant. The *team 23* analysis included league, position, referee and player as covariates. Of those only player is a significant covariate. Using crude mathematics, one might make the case that the added effect of players is the reason for moving the overall effect from the median, roughly 1.25 to 1.30. Though that's more speculation than causal reasoning.  As mentioned above, the roughly 90% of all outcome were statistically significant, given that only 27% of the covariates have an overall significant effects suggest that the effect is of skin tone itself is fairly robust. \newline

```{r covar_plot, echo = FALSE, fig.width = 8, fig.align = "center", fig.cap = "The specified covariate effects indicate the extend to which a covariate influences the outcome measures."}

dat_covariates = dat_covariates[order(dat_covariates$estimate_oddsratio), ]

covariate_effects = dat_covariates %>%
  ggplot(aes(x = reorder(x = impact_names, X = impact_coef), impact_coef)) +
  geom_point(aes(color = below_alpha)) +
  geom_hline(yintercept = 0) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper, color = below_alpha), width = 0.1) +
  scale_color_manual(values = c("red", "black")) +
  scale_y_continuous(name = "Estimates",
                     labels = scales::comma_format(accuracy = 0.05), breaks = c(seq(-0.15, 0.15, 0.05)), limits = c(-0.15, 0.15)) +
  labs(title = "Specified covariate effects",
       subtitle = paste0("N = ", nrow(analysed_specifications), ", 95% CI", collapse = ""), x = "Covariates") +
  theme_classic() +
  theme(panel.grid.major.y = element_line(colour = "grey"),
        axis.text.x = element_text(angle = 45, hjust = 1),
        plot.margin = unit(c(0.5, 1, 0.5, 1), "cm"),
        legend.position = "top",
        legend.justification = "right",
        legend.title.align = 1,
        legend.text = element_text(size = 10),
        legend.direction = "horizontal",
        legend.title = element_blank(),
        legend.margin = margin(t = -0.33, b = -0.2, unit = "cm"),
        legend.box.margin = margin(t = -0.33, b = -0.2, unit = "cm"),
        plot.title = element_text(face = "bold"),
        plot.subtitle = element_text(face = "italic"),
        text = element_text(size = 10)) +
  guides(colour = guide_legend(reverse = TRUE))

covariate_effects

```


```{r volcano_plot, echo = FALSE, fig.width = 8, fig.align = "center"}

volcano_plot = dat_models_specifications %>% 
  filter(estimate_oddsratio < 4) %>% 
  ggplot(aes(estimate_oddsratio, log10(p_value))) +
  geom_point(aes(colour = below_alpha), alpha = 0.3) +
  scale_x_continuous(name = "Odds ratios", breaks = c(seq(1.0, 1.5, 0.05)), limits = c(0.99, 1.51), expand = c(0, 0)) +
  scale_y_continuous(name = "Log10 p-value") +
  scale_color_manual(values = c("red", "black")) +
  labs(title = "Vibration of Effect",
       subtitle = paste0("N = ", nrow(analysed_specifications), collapse = "")) +
  theme_classic() +
  theme(panel.grid.major = element_line(colour = "grey"),
        plot.margin = unit(c(0.5, 1, 0.5, 1), "cm"),
        legend.position = "top",
        legend.justification = "right",
        legend.title.align = 1,
        legend.text = element_text(size = 10),
        legend.direction = "horizontal",
        legend.title = element_blank(),
        legend.margin = margin(t = -0.6, b = -0.2, unit = "cm"),
        legend.box.margin = margin(t = -0.6, b = -0.2, unit = "cm"),
        plot.title = element_text(face = "bold"),
        plot.subtitle = element_text(face = "italic", margin = margin(0, 0, 20, 0)),
        text = element_text(size = 10)) +
  guides(colour = guide_legend(override.aes = list(alpha = 1, size = 1), reverse = TRUE))

volcano_plot

```


\newpage

# Discussion
The current project used multiverse analysis to define the results space of the @silberzahn2018. Among others multiverse analysis combines different statistical modelling approaches along with covariate combinations. The goals is assess the robustness of effects. Due to time and resources limitations, I chose to focus on statistical modelling approach, but explore every possible covariate combination. Usually, multiverse analysis would focus on all plausible (or reasonable) analytic strategies. However, this project sought to define the results space of all *possible* analytical outcomes to investigate in which space the outcomes of the *plausible* analytical strategies vary in the first place. Only if the results space is defined, is possible assess its content. The concept of statistical association, provided a neat analogy. There is covariation and correlation, both quantify the variability of two variables. Both indicate the direction of relationship (positive, none, negative). However, to assess the strength of the relationship only correlation is informative. Correlation is the standardised version of covariation, hence, it has a scale to it. And only knowing the limits to space of variation gives the correlation coefficient meaning. The same applies to analyses on a broader level. If researchers want to be able to tell if their analysis reflects a true effect or simply a luck guess, they need to know the entire results space. Only then they can identify the robustness of effects.

     Due to time and resource limitation this project focused on pne

In order to assess the strength of the association covariation is hardly useful as covariate it does not have a standarised scale to it.


\newpage
# References